{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package punkt to /Users/matt/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /Users/matt/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /Users/matt/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../data/DisasterResponse.db')\n",
    "df = pd.read_sql('select * from Message_Category'\n",
    "                ,engine)\n",
    "# check top df rows                 \n",
    "df.head()\n",
    "# create feature matrix\n",
    "X = df['message']\n",
    "# response matrix\n",
    "Y = df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(26028,)\n(26028, 35)\n"
    }
   ],
   "source": [
    "# there is one feature column to be used and 35 label columns due to dropping child_alone column in ETL process.\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenization function to process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Title: Text pre-processing function.\n",
    "    Input: Raw text data\n",
    "    Output: Normalized, stop words removed, tokenized, stemmed and lemmatized text data.\n",
    "    '''\n",
    "    # Normalize text.\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' '\n",
    "                 ,text.lower())\n",
    "    # Instantiate stop words             \n",
    "    stop_words = stopwords.words('english')\n",
    "    # Tokenize words\n",
    "    words = word_tokenize(text)\n",
    "    # Stemming\n",
    "    stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "    # Lemmatize\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w) for w in stemmed if w not in stop_words]\n",
    "\n",
    "    return (lemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a pipeline\n",
    "pipeline = Pipeline([('vect', CountVectorizer(tokenizer = tokenize))\n",
    "                    ,('tfidf', TfidfTransformer())\n",
    "                    ,('clf', MultiOutputClassifier(RandomForestClassifier()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('vect',\n                 CountVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n                                 input='content', lowercase=True, max_df=1.0,\n                                 max_features=None, min_df=1,\n                                 ngram_range=(1, 1), preprocessor=None,\n                                 stop_words=None, strip_accents=None,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function tokenize at...\n                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n                                                                        class_weight=None,\n                                                                        criterion='gini',\n                                                                        max_depth=None,\n                                                                        max_features='auto',\n                                                                        max_leaf_nodes=None,\n                                                                        min_impurity_decrease=0.0,\n                                                                        min_impurity_split=None,\n                                                                        min_samples_leaf=1,\n                                                                        min_samples_split=2,\n                                                                        min_weight_fraction_leaf=0.0,\n                                                                        n_estimators='warn',\n                                                                        n_jobs=None,\n                                                                        oob_score=False,\n                                                                        random_state=None,\n                                                                        verbose=0,\n                                                                        warm_start=False),\n                                       n_jobs=None))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# train classifier\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(Y_test, Y_pred):\n",
    "    '''\n",
    "    Title: Function to get f1 score, precision and recall for each label category column.\n",
    "    Input: True Values (y_test), Predicted values (y_pred).\n",
    "    Output: Results dataframe.\n",
    "    '''\n",
    "    # create empty dataframe with columns of interest\n",
    "    results = pd.DataFrame(columns = ['Category', 'f_score', 'precision', 'recall'])\n",
    "    num = 0\n",
    "\n",
    "    # looping through y_test columns\n",
    "    for cat in Y_test.columns:\n",
    "        precision, recall, f_score, support = precision_recall_fscore_support(Y_test[cat], Y_pred[:, num], average = 'weighted')\n",
    "        results.at[num + 1, 'Category'] = cat\n",
    "        results.at[num+1, 'f_score'] = f_score\n",
    "        results.at[num+1, 'precision'] = precision\n",
    "        results.at[num+1, 'recall'] = recall\n",
    "        num += 1\n",
    "    # get Total average results    \n",
    "    print('Average f_score:', results['f_score'].mean())\n",
    "    print('Average precision:', results['precision'].mean())\n",
    "    print('Average recall:', results['recall'].mean())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average f_score: 0.9316024227007785\nAverage precision: 0.9324557542358791\nAverage recall: 0.9437748358910186\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                  Category   f_score precision    recall\n1                  related  0.799154  0.796532  0.809897\n2                  request  0.874519  0.879846  0.887659\n3                    offer   0.99332  0.991106  0.995543\n4              aid_related  0.751252  0.755542  0.756109\n5             medical_help  0.902998  0.909394  0.927002\n6         medical_products  0.943691   0.94498  0.956969\n7        search_and_rescue  0.959316  0.958928  0.971415\n8                 security  0.974561  0.966471  0.982788\n9                 military  0.952916  0.954315  0.966498\n10                   water   0.93749  0.944256  0.950054\n11                    food  0.938183  0.937728  0.941294\n12                 shelter  0.917996  0.925626  0.931919\n13                clothing  0.979375  0.980625  0.984939\n14                   money  0.964974  0.966477  0.975872\n15          missing_people  0.986798  0.991166  0.991087\n16                refugees  0.956818   0.96146  0.969264\n17                   death  0.943256  0.953998  0.958045\n18               other_aid  0.824342  0.828039  0.871523\n19  infrastructure_related  0.897435  0.888793     0.929\n20               transport   0.93666  0.941265  0.954972\n21               buildings  0.937164  0.945222  0.953742\n22             electricity  0.968601   0.96973   0.97787\n23                   tools  0.991019  0.988049  0.994006\n24               hospitals  0.984352  0.979209   0.98955\n25                   shops  0.990942  0.988048  0.993853\n26             aid_centers  0.982667  0.977079   0.98832\n27    other_infrastructure  0.927899  0.912537  0.950822\n28         weather_related   0.85493  0.858365   0.86138\n29                  floods  0.934197  0.940865  0.944675\n30                   storm  0.925703  0.925971  0.933149\n31                    fire  0.981596  0.975562  0.987706\n32              earthquake  0.964794  0.964577  0.966037\n33                    cold  0.969642  0.967942   0.97787\n34           other_weather  0.927137  0.924812  0.947902\n35           direct_report  0.830389  0.841436  0.853389",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>f_score</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>related</td>\n      <td>0.799154</td>\n      <td>0.796532</td>\n      <td>0.809897</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>request</td>\n      <td>0.874519</td>\n      <td>0.879846</td>\n      <td>0.887659</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>offer</td>\n      <td>0.99332</td>\n      <td>0.991106</td>\n      <td>0.995543</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>aid_related</td>\n      <td>0.751252</td>\n      <td>0.755542</td>\n      <td>0.756109</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>medical_help</td>\n      <td>0.902998</td>\n      <td>0.909394</td>\n      <td>0.927002</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>medical_products</td>\n      <td>0.943691</td>\n      <td>0.94498</td>\n      <td>0.956969</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>search_and_rescue</td>\n      <td>0.959316</td>\n      <td>0.958928</td>\n      <td>0.971415</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>security</td>\n      <td>0.974561</td>\n      <td>0.966471</td>\n      <td>0.982788</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>military</td>\n      <td>0.952916</td>\n      <td>0.954315</td>\n      <td>0.966498</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>water</td>\n      <td>0.93749</td>\n      <td>0.944256</td>\n      <td>0.950054</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>food</td>\n      <td>0.938183</td>\n      <td>0.937728</td>\n      <td>0.941294</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>shelter</td>\n      <td>0.917996</td>\n      <td>0.925626</td>\n      <td>0.931919</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>clothing</td>\n      <td>0.979375</td>\n      <td>0.980625</td>\n      <td>0.984939</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>money</td>\n      <td>0.964974</td>\n      <td>0.966477</td>\n      <td>0.975872</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>missing_people</td>\n      <td>0.986798</td>\n      <td>0.991166</td>\n      <td>0.991087</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>refugees</td>\n      <td>0.956818</td>\n      <td>0.96146</td>\n      <td>0.969264</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>death</td>\n      <td>0.943256</td>\n      <td>0.953998</td>\n      <td>0.958045</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>other_aid</td>\n      <td>0.824342</td>\n      <td>0.828039</td>\n      <td>0.871523</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>infrastructure_related</td>\n      <td>0.897435</td>\n      <td>0.888793</td>\n      <td>0.929</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>transport</td>\n      <td>0.93666</td>\n      <td>0.941265</td>\n      <td>0.954972</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>buildings</td>\n      <td>0.937164</td>\n      <td>0.945222</td>\n      <td>0.953742</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>electricity</td>\n      <td>0.968601</td>\n      <td>0.96973</td>\n      <td>0.97787</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>tools</td>\n      <td>0.991019</td>\n      <td>0.988049</td>\n      <td>0.994006</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>hospitals</td>\n      <td>0.984352</td>\n      <td>0.979209</td>\n      <td>0.98955</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>shops</td>\n      <td>0.990942</td>\n      <td>0.988048</td>\n      <td>0.993853</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>aid_centers</td>\n      <td>0.982667</td>\n      <td>0.977079</td>\n      <td>0.98832</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>other_infrastructure</td>\n      <td>0.927899</td>\n      <td>0.912537</td>\n      <td>0.950822</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>weather_related</td>\n      <td>0.85493</td>\n      <td>0.858365</td>\n      <td>0.86138</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>floods</td>\n      <td>0.934197</td>\n      <td>0.940865</td>\n      <td>0.944675</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>storm</td>\n      <td>0.925703</td>\n      <td>0.925971</td>\n      <td>0.933149</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>fire</td>\n      <td>0.981596</td>\n      <td>0.975562</td>\n      <td>0.987706</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>earthquake</td>\n      <td>0.964794</td>\n      <td>0.964577</td>\n      <td>0.966037</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>cold</td>\n      <td>0.969642</td>\n      <td>0.967942</td>\n      <td>0.97787</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>other_weather</td>\n      <td>0.927137</td>\n      <td>0.924812</td>\n      <td>0.947902</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>direct_report</td>\n      <td>0.830389</td>\n      <td>0.841436</td>\n      <td>0.853389</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# get the results for our model accuracy\n",
    "results = get_results(Y_test, Y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve model with grid and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('vect',\n   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                   tokenizer=<function tokenize at 0x10d40f950>, vocabulary=None)),\n  ('tfidf',\n   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n  ('clf',\n   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n                                                          class_weight=None,\n                                                          criterion='gini',\n                                                          max_depth=None,\n                                                          max_features='auto',\n                                                          max_leaf_nodes=None,\n                                                          min_impurity_decrease=0.0,\n                                                          min_impurity_split=None,\n                                                          min_samples_leaf=1,\n                                                          min_samples_split=2,\n                                                          min_weight_fraction_leaf=0.0,\n                                                          n_estimators='warn',\n                                                          n_jobs=None,\n                                                          oob_score=False,\n                                                          random_state=None,\n                                                          verbose=0,\n                                                          warm_start=False),\n                         n_jobs=None))],\n 'verbose': False,\n 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                 tokenizer=<function tokenize at 0x10d40f950>, vocabulary=None),\n 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n                                                        class_weight=None,\n                                                        criterion='gini',\n                                                        max_depth=None,\n                                                        max_features='auto',\n                                                        max_leaf_nodes=None,\n                                                        min_impurity_decrease=0.0,\n                                                        min_impurity_split=None,\n                                                        min_samples_leaf=1,\n                                                        min_samples_split=2,\n                                                        min_weight_fraction_leaf=0.0,\n                                                        n_estimators='warn',\n                                                        n_jobs=None,\n                                                        oob_score=False,\n                                                        random_state=None,\n                                                        verbose=0,\n                                                        warm_start=False),\n                       n_jobs=None),\n 'vect__analyzer': 'word',\n 'vect__binary': False,\n 'vect__decode_error': 'strict',\n 'vect__dtype': numpy.int64,\n 'vect__encoding': 'utf-8',\n 'vect__input': 'content',\n 'vect__lowercase': True,\n 'vect__max_df': 1.0,\n 'vect__max_features': None,\n 'vect__min_df': 1,\n 'vect__ngram_range': (1, 1),\n 'vect__preprocessor': None,\n 'vect__stop_words': None,\n 'vect__strip_accents': None,\n 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n 'vect__tokenizer': <function __main__.tokenize(text)>,\n 'vect__vocabulary': None,\n 'tfidf__norm': 'l2',\n 'tfidf__smooth_idf': True,\n 'tfidf__sublinear_tf': False,\n 'tfidf__use_idf': True,\n 'clf__estimator__bootstrap': True,\n 'clf__estimator__class_weight': None,\n 'clf__estimator__criterion': 'gini',\n 'clf__estimator__max_depth': None,\n 'clf__estimator__max_features': 'auto',\n 'clf__estimator__max_leaf_nodes': None,\n 'clf__estimator__min_impurity_decrease': 0.0,\n 'clf__estimator__min_impurity_split': None,\n 'clf__estimator__min_samples_leaf': 1,\n 'clf__estimator__min_samples_split': 2,\n 'clf__estimator__min_weight_fraction_leaf': 0.0,\n 'clf__estimator__n_estimators': 'warn',\n 'clf__estimator__n_jobs': None,\n 'clf__estimator__oob_score': False,\n 'clf__estimator__random_state': None,\n 'clf__estimator__verbose': 0,\n 'clf__estimator__warm_start': False,\n 'clf__estimator': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n                        min_impurity_decrease=0.0, min_impurity_split=None,\n                        min_samples_leaf=1, min_samples_split=2,\n                        min_weight_fraction_leaf=0.0, n_estimators='warn',\n                        n_jobs=None, oob_score=False, random_state=None,\n                        verbose=0, warm_start=False),\n 'clf__n_jobs': None}"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# check for pipeline parameters for grid search cv\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to long execution time I have limited number of parameters to cross validate to minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create parameters for grid\n",
    "parameters = {'clf__estimator__min_samples_leaf': [1, 3, 5]} # minimum samples at each leaf node\n",
    "    \n",
    "# create grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv='warn', error_score='raise-deprecating',\n             estimator=Pipeline(memory=None,\n                                steps=[('vect',\n                                        CountVectorizer(analyzer='word',\n                                                        binary=False,\n                                                        decode_error='strict',\n                                                        dtype=<class 'numpy.int64'>,\n                                                        encoding='utf-8',\n                                                        input='content',\n                                                        lowercase=True,\n                                                        max_df=1.0,\n                                                        max_features=None,\n                                                        min_df=1,\n                                                        ngram_range=(1, 1),\n                                                        preprocessor=None,\n                                                        stop_words=None,\n                                                        strip_accents=Non...\n                                                                                               min_samples_leaf=1,\n                                                                                               min_samples_split=2,\n                                                                                               min_weight_fraction_leaf=0.0,\n                                                                                               n_estimators='warn',\n                                                                                               n_jobs=None,\n                                                                                               oob_score=False,\n                                                                                               random_state=None,\n                                                                                               verbose=0,\n                                                                                               warm_start=False),\n                                                              n_jobs=None))],\n                                verbose=False),\n             iid='warn', n_jobs=None,\n             param_grid={'clf__estimator__min_samples_leaf': [1]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=0)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# check the grid\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv='warn', error_score='raise-deprecating',\n             estimator=Pipeline(memory=None,\n                                steps=[('vect',\n                                        CountVectorizer(analyzer='word',\n                                                        binary=False,\n                                                        decode_error='strict',\n                                                        dtype=<class 'numpy.int64'>,\n                                                        encoding='utf-8',\n                                                        input='content',\n                                                        lowercase=True,\n                                                        max_df=1.0,\n                                                        max_features=None,\n                                                        min_df=1,\n                                                        ngram_range=(1, 1),\n                                                        preprocessor=None,\n                                                        stop_words=None,\n                                                        strip_accents=Non...\n                                                                                               min_samples_leaf=1,\n                                                                                               min_samples_split=2,\n                                                                                               min_weight_fraction_leaf=0.0,\n                                                                                               n_estimators='warn',\n                                                                                               n_jobs=None,\n                                                                                               oob_score=False,\n                                                                                               random_state=None,\n                                                                                               verbose=0,\n                                                                                               warm_start=False),\n                                                              n_jobs=None))],\n                                verbose=False),\n             iid='warn', n_jobs=None,\n             param_grid={'clf__estimator__min_samples_leaf': [1]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=0)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# fit the grid (takes forever!)\n",
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Done!\n"
    }
   ],
   "source": [
    "# predict on grid\n",
    "Y_pred = cv.predict(X_test)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average f_score: 0.9314155019066263\nAverage precision: 0.9321533391701008\nAverage recall: 0.9433664844453227\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                  Category   f_score precision    recall\n1                  related  0.797461  0.794491  0.807746\n2                  request  0.870816  0.874203  0.883664\n3                    offer   0.99332  0.991106  0.995543\n4              aid_related  0.747741  0.751736  0.752574\n5             medical_help  0.904758  0.908588  0.927002\n6         medical_products  0.941381  0.941069  0.955586\n7        search_and_rescue  0.958086  0.952986  0.970647\n8                 security  0.974407  0.966466   0.98248\n9                 military  0.954263  0.957221  0.967112\n10                   water  0.945742  0.950335  0.954818\n11                    food  0.925569  0.927886  0.932688\n12                 shelter  0.912048   0.92327     0.929\n13                clothing  0.981485  0.982222  0.985708\n14                   money  0.965334  0.967924  0.976026\n15          missing_people  0.987167  0.991317   0.99124\n16                refugees  0.955189  0.958915  0.968649\n17                   death  0.942947  0.953716  0.957892\n18               other_aid  0.825327  0.830381  0.871984\n19  infrastructure_related  0.896285  0.878956     0.929\n20               transport  0.940237  0.944998  0.956201\n21               buildings  0.940846  0.949325  0.955586\n22             electricity  0.967987  0.968816  0.977716\n23                   tools  0.991019  0.988049  0.994006\n24               hospitals  0.984352  0.979209   0.98955\n25                   shops  0.991019  0.988049  0.994006\n26             aid_centers  0.982744  0.977081  0.988474\n27    other_infrastructure  0.927899  0.912537  0.950822\n28         weather_related  0.856721  0.859664  0.862763\n29                  floods  0.940381  0.944051   0.94821\n30                   storm  0.926245  0.925859  0.932995\n31                    fire  0.982264  0.984057  0.987859\n32              earthquake  0.960357  0.960611  0.962502\n33                    cold  0.976112  0.977113  0.981097\n34           other_weather  0.928674  0.929944  0.948824\n35           direct_report  0.823361  0.833218  0.847856",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>f_score</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>related</td>\n      <td>0.797461</td>\n      <td>0.794491</td>\n      <td>0.807746</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>request</td>\n      <td>0.870816</td>\n      <td>0.874203</td>\n      <td>0.883664</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>offer</td>\n      <td>0.99332</td>\n      <td>0.991106</td>\n      <td>0.995543</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>aid_related</td>\n      <td>0.747741</td>\n      <td>0.751736</td>\n      <td>0.752574</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>medical_help</td>\n      <td>0.904758</td>\n      <td>0.908588</td>\n      <td>0.927002</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>medical_products</td>\n      <td>0.941381</td>\n      <td>0.941069</td>\n      <td>0.955586</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>search_and_rescue</td>\n      <td>0.958086</td>\n      <td>0.952986</td>\n      <td>0.970647</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>security</td>\n      <td>0.974407</td>\n      <td>0.966466</td>\n      <td>0.98248</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>military</td>\n      <td>0.954263</td>\n      <td>0.957221</td>\n      <td>0.967112</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>water</td>\n      <td>0.945742</td>\n      <td>0.950335</td>\n      <td>0.954818</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>food</td>\n      <td>0.925569</td>\n      <td>0.927886</td>\n      <td>0.932688</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>shelter</td>\n      <td>0.912048</td>\n      <td>0.92327</td>\n      <td>0.929</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>clothing</td>\n      <td>0.981485</td>\n      <td>0.982222</td>\n      <td>0.985708</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>money</td>\n      <td>0.965334</td>\n      <td>0.967924</td>\n      <td>0.976026</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>missing_people</td>\n      <td>0.987167</td>\n      <td>0.991317</td>\n      <td>0.99124</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>refugees</td>\n      <td>0.955189</td>\n      <td>0.958915</td>\n      <td>0.968649</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>death</td>\n      <td>0.942947</td>\n      <td>0.953716</td>\n      <td>0.957892</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>other_aid</td>\n      <td>0.825327</td>\n      <td>0.830381</td>\n      <td>0.871984</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>infrastructure_related</td>\n      <td>0.896285</td>\n      <td>0.878956</td>\n      <td>0.929</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>transport</td>\n      <td>0.940237</td>\n      <td>0.944998</td>\n      <td>0.956201</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>buildings</td>\n      <td>0.940846</td>\n      <td>0.949325</td>\n      <td>0.955586</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>electricity</td>\n      <td>0.967987</td>\n      <td>0.968816</td>\n      <td>0.977716</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>tools</td>\n      <td>0.991019</td>\n      <td>0.988049</td>\n      <td>0.994006</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>hospitals</td>\n      <td>0.984352</td>\n      <td>0.979209</td>\n      <td>0.98955</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>shops</td>\n      <td>0.991019</td>\n      <td>0.988049</td>\n      <td>0.994006</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>aid_centers</td>\n      <td>0.982744</td>\n      <td>0.977081</td>\n      <td>0.988474</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>other_infrastructure</td>\n      <td>0.927899</td>\n      <td>0.912537</td>\n      <td>0.950822</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>weather_related</td>\n      <td>0.856721</td>\n      <td>0.859664</td>\n      <td>0.862763</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>floods</td>\n      <td>0.940381</td>\n      <td>0.944051</td>\n      <td>0.94821</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>storm</td>\n      <td>0.926245</td>\n      <td>0.925859</td>\n      <td>0.932995</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>fire</td>\n      <td>0.982264</td>\n      <td>0.984057</td>\n      <td>0.987859</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>earthquake</td>\n      <td>0.960357</td>\n      <td>0.960611</td>\n      <td>0.962502</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>cold</td>\n      <td>0.976112</td>\n      <td>0.977113</td>\n      <td>0.981097</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>other_weather</td>\n      <td>0.928674</td>\n      <td>0.929944</td>\n      <td>0.948824</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>direct_report</td>\n      <td>0.823361</td>\n      <td>0.833218</td>\n      <td>0.847856</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# get the results\n",
    "cv_results = get_results(Y_test, Y_pred)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('vect',\n                 CountVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n                                 input='content', lowercase=True, max_df=1.0,\n                                 max_features=None, min_df=1,\n                                 ngram_range=(1, 1), preprocessor=None,\n                                 stop_words=None, strip_accents=None,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function tokenize at...\n                 MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n                                                                        class_weight=None,\n                                                                        criterion='gini',\n                                                                        max_depth=None,\n                                                                        max_features='auto',\n                                                                        max_leaf_nodes=None,\n                                                                        min_impurity_decrease=0.0,\n                                                                        min_impurity_split=None,\n                                                                        min_samples_leaf=1,\n                                                                        min_samples_split=2,\n                                                                        min_weight_fraction_leaf=0.0,\n                                                                        n_estimators='warn',\n                                                                        n_jobs=None,\n                                                                        oob_score=False,\n                                                                        random_state=None,\n                                                                        verbose=0,\n                                                                        warm_start=False),\n                                       n_jobs=None))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# view the best parameters\n",
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try to improve model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('vect',\n                 CountVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n                                 input='content', lowercase=True, max_df=1.0,\n                                 max_features=None, min_df=1,\n                                 ngram_range=(1, 1), preprocessor=None,\n                                 stop_words=None, strip_accents=None,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function tokenize at...\n                 TfidfTransformer(norm='l2', smooth_idf=True,\n                                  sublinear_tf=False, use_idf=True)),\n                ('clf',\n                 MultiOutputClassifier(estimator=SVC(C=1.0, cache_size=200,\n                                                     class_weight=None,\n                                                     coef0=0.0,\n                                                     decision_function_shape='ovr',\n                                                     degree=3,\n                                                     gamma='auto_deprecated',\n                                                     kernel='rbf', max_iter=-1,\n                                                     probability=False,\n                                                     random_state=None,\n                                                     shrinking=True, tol=0.001,\n                                                     verbose=False),\n                                       n_jobs=None))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# testing a Support Vector Classifier\n",
    "pipeline = Pipeline([('vect', CountVectorizer(tokenizer=tokenize))\n",
    "                    ,('tfidf', TfidfTransformer())\n",
    "                    ,('clf', MultiOutputClassifier(SVC()))\n",
    "                    ])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average f_score: 0.889393331101731\nAverage precision: 0.8608332711427559\nAverage recall: 0.9236382796548773\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                  Category   f_score precision    recall\n1                  related  0.660672  0.582441  0.763178\n2                  request  0.744971  0.679541  0.824343\n3                    offer  0.992629  0.990189  0.995082\n4              aid_related  0.435239  0.345542  0.587828\n5             medical_help  0.879329   0.84345  0.918396\n6         medical_products  0.928893  0.906695  0.952205\n7        search_and_rescue  0.955048  0.940664  0.969879\n8                 security  0.970362  0.960743  0.980175\n9                 military  0.955733  0.941559   0.97034\n10                   water  0.902005  0.872202  0.933917\n11                    food  0.836159  0.789577  0.888582\n12                 shelter  0.867707  0.828836  0.910404\n13                clothing  0.979072  0.972226  0.986015\n14                   money  0.966471  0.955629  0.977563\n15          missing_people  0.984811  0.979817  0.989857\n16                refugees  0.948209  0.931743  0.965268\n17                   death  0.930707  0.909038  0.953435\n18               other_aid  0.805113  0.751537  0.866913\n19  infrastructure_related  0.899079  0.868474  0.931919\n20               transport  0.934111  0.913439   0.95574\n21               buildings  0.918026  0.892701  0.944829\n22             electricity   0.96876  0.958636  0.979099\n23                   tools  0.992399  0.989883  0.994929\n24               hospitals  0.982974  0.977385  0.988628\n25                   shops  0.992169  0.989577  0.994775\n26             aid_centers  0.980678  0.974348  0.987091\n27    other_infrastructure   0.93343  0.912558  0.955279\n28         weather_related  0.602376  0.517949  0.719686\n29                  floods  0.880896  0.845428  0.919471\n30                   storm  0.855677  0.813794  0.902105\n31                    fire  0.982515  0.976777   0.98832\n32              earthquake  0.857457  0.816014  0.903335\n33                    cold  0.969675   0.95984  0.979714\n34           other_weather  0.925494   0.90231    0.9499\n35           direct_report  0.709921  0.638624  0.799139",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>f_score</th>\n      <th>precision</th>\n      <th>recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>related</td>\n      <td>0.660672</td>\n      <td>0.582441</td>\n      <td>0.763178</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>request</td>\n      <td>0.744971</td>\n      <td>0.679541</td>\n      <td>0.824343</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>offer</td>\n      <td>0.992629</td>\n      <td>0.990189</td>\n      <td>0.995082</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>aid_related</td>\n      <td>0.435239</td>\n      <td>0.345542</td>\n      <td>0.587828</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>medical_help</td>\n      <td>0.879329</td>\n      <td>0.84345</td>\n      <td>0.918396</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>medical_products</td>\n      <td>0.928893</td>\n      <td>0.906695</td>\n      <td>0.952205</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>search_and_rescue</td>\n      <td>0.955048</td>\n      <td>0.940664</td>\n      <td>0.969879</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>security</td>\n      <td>0.970362</td>\n      <td>0.960743</td>\n      <td>0.980175</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>military</td>\n      <td>0.955733</td>\n      <td>0.941559</td>\n      <td>0.97034</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>water</td>\n      <td>0.902005</td>\n      <td>0.872202</td>\n      <td>0.933917</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>food</td>\n      <td>0.836159</td>\n      <td>0.789577</td>\n      <td>0.888582</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>shelter</td>\n      <td>0.867707</td>\n      <td>0.828836</td>\n      <td>0.910404</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>clothing</td>\n      <td>0.979072</td>\n      <td>0.972226</td>\n      <td>0.986015</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>money</td>\n      <td>0.966471</td>\n      <td>0.955629</td>\n      <td>0.977563</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>missing_people</td>\n      <td>0.984811</td>\n      <td>0.979817</td>\n      <td>0.989857</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>refugees</td>\n      <td>0.948209</td>\n      <td>0.931743</td>\n      <td>0.965268</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>death</td>\n      <td>0.930707</td>\n      <td>0.909038</td>\n      <td>0.953435</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>other_aid</td>\n      <td>0.805113</td>\n      <td>0.751537</td>\n      <td>0.866913</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>infrastructure_related</td>\n      <td>0.899079</td>\n      <td>0.868474</td>\n      <td>0.931919</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>transport</td>\n      <td>0.934111</td>\n      <td>0.913439</td>\n      <td>0.95574</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>buildings</td>\n      <td>0.918026</td>\n      <td>0.892701</td>\n      <td>0.944829</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>electricity</td>\n      <td>0.96876</td>\n      <td>0.958636</td>\n      <td>0.979099</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>tools</td>\n      <td>0.992399</td>\n      <td>0.989883</td>\n      <td>0.994929</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>hospitals</td>\n      <td>0.982974</td>\n      <td>0.977385</td>\n      <td>0.988628</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>shops</td>\n      <td>0.992169</td>\n      <td>0.989577</td>\n      <td>0.994775</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>aid_centers</td>\n      <td>0.980678</td>\n      <td>0.974348</td>\n      <td>0.987091</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>other_infrastructure</td>\n      <td>0.93343</td>\n      <td>0.912558</td>\n      <td>0.955279</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>weather_related</td>\n      <td>0.602376</td>\n      <td>0.517949</td>\n      <td>0.719686</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>floods</td>\n      <td>0.880896</td>\n      <td>0.845428</td>\n      <td>0.919471</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>storm</td>\n      <td>0.855677</td>\n      <td>0.813794</td>\n      <td>0.902105</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>fire</td>\n      <td>0.982515</td>\n      <td>0.976777</td>\n      <td>0.98832</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>earthquake</td>\n      <td>0.857457</td>\n      <td>0.816014</td>\n      <td>0.903335</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>cold</td>\n      <td>0.969675</td>\n      <td>0.95984</td>\n      <td>0.979714</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>other_weather</td>\n      <td>0.925494</td>\n      <td>0.90231</td>\n      <td>0.9499</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>direct_report</td>\n      <td>0.709921</td>\n      <td>0.638624</td>\n      <td>0.799139</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "results_SVC = get_results(Y_test, Y_pred)\n",
    "results_SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv, open('..models/model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}